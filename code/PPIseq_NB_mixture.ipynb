{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "# import torch.distributions.constraints as constraints\n",
    "# import torch.distributions as tdist\n",
    "import pyro\n",
    "import pyro.infer\n",
    "import pyro.optim\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer.autoguide import AutoNormal\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "\n",
    "pyro.set_rng_seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['reads_edited', 'reads_unedited', 'size_factors', 'fit_dispersions', 'design_matrix'])\n"
     ]
    }
   ],
   "source": [
    "data = pkl.load(open(\"/data/pinello/PROJECTS/2022_PPIseq/data/1028/1028_pyro_dict.pkl\", \"rb\"))\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>1H</th>\n",
       "      <th>3H</th>\n",
       "      <th>EditEnriched</th>\n",
       "      <th>MEM</th>\n",
       "      <th>NLS</th>\n",
       "      <th>OMM</th>\n",
       "      <th>NES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MEM_H1M_1H</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEM_H1M_3H</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NES_H1M_1H</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NES_H1M_3H</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLS_H1M_1H</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLS_H1M_3H</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OMM_1H</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OMM_3H</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Baseline  1H  3H  EditEnriched  MEM  NLS  OMM  NES\n",
       "MEM_H1M_1H         1   1   0             0    1    0    0    0\n",
       "MEM_H1M_3H         1   0   1             0    1    0    0    0\n",
       "NES_H1M_1H         1   1   0             0    0    0    0    1\n",
       "NES_H1M_3H         1   0   1             0    0    0    0    1\n",
       "NLS_H1M_1H         1   1   0             0    0    1    0    0\n",
       "NLS_H1M_3H         1   0   1             0    0    1    0    0\n",
       "OMM_1H             1   1   0             0    0    0    1    0\n",
       "OMM_3H             1   0   1             0    0    0    1    0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"design_matrix\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " data contains:\n",
    " - reads_edited, shape: [len(replicates), len(orfs), len(tags)*len(times)]\n",
    "\n",
    " - reads_unedited, shape: [len(replicates), len(orfs), len(tags)*len(times)]\n",
    "\n",
    " - size_factors, shape: [len(replicates), len(tags)*len(times)]\n",
    "\n",
    " - fit_dispersions, shape: [len(orfs), len(tags)*len(times)]\n",
    "\n",
    " - design matrix, shape: [len(tags)*len(times), len(betas)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_NB_mixture(data):\n",
    "    n_tags, n_orfs, n_reps = data[\"reads_edited\"].shape\n",
    "    dispersion_var = 1\n",
    "\n",
    "    with pyro.plate(\"Experiments (ABE-Tags)\", n_tags):\n",
    "        # All betas per experiment\n",
    "        # unsure of dists here\n",
    "        beta_exp_0 = pyro.sample(\"β_Exp_0\", dist.Normal(0, 1))\n",
    "        # beta_exp_1\n",
    "        # beta_exp_2\n",
    "        # ...\n",
    "        beta_exp = torch.Tensor([beta_exp_0])  # , beta_exp_1, beta_exp_2]\n",
    "\n",
    "        with pyro.plate(\"MCP-ORFs\", n_orfs):\n",
    "            # unsure of dists here\n",
    "            beta_int_0 = pyro.sample(\"β_Int_0\", dist.Normal(0, 1))\n",
    "            # beta_int_1\n",
    "            # beta_int_2\n",
    "            # ...\n",
    "            beta_int = torch.Tensor([beta_int_0])  # , beta_int_1, beta_int_2]\n",
    "\n",
    "            dispersion = pyro.sample(\n",
    "                \"φ\", dist.LogNormal(data[\"fit_dispersions\"].log(), dispersion_var)\n",
    "            )\n",
    "            assert dispersion.shape == (n_orfs, n_tags)\n",
    "\n",
    "            with pyro.plate(\"Replicates\", n_reps):\n",
    "                # need to test these shapes\n",
    "                log_q = (\n",
    "                    torch.inner(beta_exp, data[\"D_Exp\"])\n",
    "                    .unsqueeze(0)\n",
    "                    .unsqueeze(0)\n",
    "                    .expand(n_reps, n_orfs, -1)\n",
    "                )\n",
    "                pi = (\n",
    "                    torch.exp(torch.inner(beta_int, data[\"D_Exp\"]))\n",
    "                    .unsqueeze(0)\n",
    "                    .unsqueeze(0)\n",
    "                    .expand(n_reps, n_orfs, -1)\n",
    "                )\n",
    "\n",
    "                assert log_q.shape == pi.shape == (n_reps, n_orfs, n_tags)\n",
    "\n",
    "                logits_U = (\n",
    "                    log_q\n",
    "                    + torch.log(1 - pi)\n",
    "                    + torch.log(data[\"size_factors\"])\n",
    "                    - torch.log(dispersion[None, :, :])\n",
    "                )\n",
    "                logits_E = (\n",
    "                    log_q\n",
    "                    + torch.log(pi)\n",
    "                    + torch.log(data[\"size_factor\"])\n",
    "                    - torch.log(dispersion[None, :, :])\n",
    "                )\n",
    "\n",
    "                dist_U = dist.NegativeBinomial(dispersion, logits=logits_E)\n",
    "                dist_E = dist.NegativeBinomial(dispersion, logits=logits_U)\n",
    "\n",
    "                pyro.sample(\"x_U\", dist_U, obs=data[\"reads_edited\"])\n",
    "                pyro.sample(\"x_E\", dist_E, obs=data[\"reads_edited\"])\n",
    "\n",
    "\n",
    "pyro.render_model(model_NB_mixture(data), render_params=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guide = AutoNormal(model_NB_mixture, init_scale=0.01)\n",
    "\n",
    "pyro.clear_param_store()\n",
    "initial_lr = 0.05\n",
    "gamma = 0.1  # final learning rate will be gamma * initial_lr\n",
    "num_steps = 2000\n",
    "lrd = gamma ** (1 / num_steps)\n",
    "svi = pyro.infer.SVI(\n",
    "    model=model_NB_mixture,\n",
    "    guide=guide,\n",
    "    optim=pyro.optim.ClippedAdam({\"lr\": initial_lr, \"lrd\": lrd}),\n",
    "    loss=pyro.infer.Trace_ELBO(max_plate_nesting=3),\n",
    ")\n",
    "\n",
    "\n",
    "# keep track of anything meaningful here\n",
    "beta1s, beta1_vars, beta0s, beta0_vars, dm, dv, api, bpi, pis, losses = (\n",
    "    [] for _ in range(10)\n",
    ")\n",
    "\n",
    "for t in range(num_steps):\n",
    "    losses.append(svi.step(data))\n",
    "    if t == 1:\n",
    "        print(pyro.get_param_store())\n",
    "    beta1s.append(pyro.param(\"AutoNormal.locs.beta_1\").clone())\n",
    "    beta1_vars.append(pyro.param(\"AutoNormal.scales.beta_1\"))\n",
    "    beta0s.append(pyro.param(\"AutoNormal.locs.beta_0\").clone())\n",
    "    beta0_vars.append(pyro.param(\"AutoNormal.scales.beta_0\"))\n",
    "    dm.append(pyro.param(\"AutoNormal.locs.dispersion\").clone())\n",
    "    dv.append(pyro.param(\"AutoNormal.scales.dispersion\"))\n",
    "    api.append(pyro.param(\"alpha_pi\").clone().detach())\n",
    "    bpi.append(pyro.param(\"beta_pi\").clone().detach())\n",
    "    a = pyro.param(\"alpha_pi\").clone().detach()\n",
    "    b = pyro.param(\"beta_pi\").clone().detach()\n",
    "    pis.append(a / (a + b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jd_pyro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3cdaaedb1fa9f528ee10659353db3bd8a1bd8f0894a9cc3b9b974535b18ad13"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
