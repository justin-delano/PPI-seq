{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "# import torch.distributions.constraints as constraints\n",
    "# import torch.distributions as tdist\n",
    "import pyro\n",
    "import pyro.infer\n",
    "import pyro.optim\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer.autoguide import AutoNormal\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tqdm import tqdm\n",
    "# import pickle as pkl\n",
    "\n",
    "pyro.set_rng_seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " data contains:\n",
    " - reads_edited, shape: [len(tags), len(orfs), len(replicates)]\n",
    " - reads_unedited, shape: [len(tags), len(orfs), len(replicates)]\n",
    " - size_factors, shape: [len(tags), len(orfs), len(replicates)]\n",
    " - fit_dispersions, shape: [len(tags), len(orfs)]\n",
    "\n",
    " also need:\n",
    "- beta_exp design matrix for experimental covariates\n",
    "- beta_int design matrix for interaction covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_NB_mixture(data):\n",
    "    n_tags, n_orfs, n_reps = data[\"reads_edited\"].size()\n",
    "    dispersion_var = 1\n",
    "\n",
    "    with pyro.plate(\"Experiments (ABE-Tags)\", n_tags):\n",
    "        # All betas per experiment\n",
    "        # unsure of dists here\n",
    "        beta_exp_0 = pyro.sample(\"β_Exp_0\", dist.Normal(0, 1))\n",
    "        # beta_exp_1\n",
    "        # beta_exp_2\n",
    "        # ...\n",
    "        beta_exp = torch.Tensor([beta_exp_0])  # , beta_exp_1, beta_exp_2]\n",
    "\n",
    "        with pyro.plate(\"MCP-ORFs\", n_orfs):\n",
    "            # unsure of dists here\n",
    "            beta_int_0 = pyro.sample(\"β_Int_0\", dist.Normal(0, 1))\n",
    "            # beta_int_1\n",
    "            # beta_int_2\n",
    "            # ...\n",
    "            beta_int = torch.Tensor([beta_int_0])  # , beta_int_1, beta_int_2]\n",
    "\n",
    "            dispersion = pyro.sample(\n",
    "                \"φ\", dist.LogNormal(data[\"fit_dispersions\"].log(), dispersion_var)\n",
    "            )\n",
    "            assert dispersion.shape == (n_orfs, n_tags)\n",
    "\n",
    "            with pyro.plate(\"Replicates\", n_reps):\n",
    "                # need to test these shapes\n",
    "                log_q = (\n",
    "                    torch.inner(beta_exp, data[\"D_Exp\"])\n",
    "                    .unsqueeze(0)\n",
    "                    .unsqueeze(0)\n",
    "                    .expand(n_reps, n_orfs, -1)\n",
    "                )\n",
    "                pi = (\n",
    "                    torch.exp(torch.inner(beta_int, data[\"D_Exp\"]))\n",
    "                    .unsqueeze(0)\n",
    "                    .unsqueeze(0)\n",
    "                    .expand(n_reps, n_orfs, -1)\n",
    "                )\n",
    "\n",
    "                assert log_q.shape == pi.shape == (n_reps, n_orfs, n_tags)\n",
    "\n",
    "                logits_U = (\n",
    "                    log_q\n",
    "                    + torch.log(1 - pi)\n",
    "                    + torch.log(data[\"size_factors\"])\n",
    "                    - torch.log(dispersion[None, :, :])\n",
    "                )\n",
    "                logits_E = (\n",
    "                    log_q\n",
    "                    + torch.log(pi)\n",
    "                    + torch.log(data[\"size_factor\"])\n",
    "                    - torch.log(dispersion[None, :, :])\n",
    "                )\n",
    "\n",
    "                dist_U = dist.NegativeBinomial(dispersion, logits=logits_E)\n",
    "                dist_E = dist.NegativeBinomial(dispersion, logits=logits_U)\n",
    "\n",
    "                pyro.sample(\"x_U\", dist_U, obs=data[\"reads_edited\"])\n",
    "                pyro.sample(\"x_E\", dist_E, obs=data[\"reads_edited\"])\n",
    "\n",
    "\n",
    "# pyro.render_model(model_NB_mixture, render_params=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guide = AutoNormal(model_NB_mixture, init_scale=0.01)\n",
    "\n",
    "pyro.clear_param_store()\n",
    "initial_lr = 0.05\n",
    "gamma = 0.1  # final learning rate will be gamma * initial_lr\n",
    "num_steps = 2000\n",
    "lrd = gamma ** (1 / num_steps)\n",
    "svi = pyro.infer.SVI(\n",
    "    model=model_NB_mixture,\n",
    "    guide=guide,\n",
    "    optim=pyro.optim.ClippedAdam({\"lr\": initial_lr, \"lrd\": lrd}),\n",
    "    loss=pyro.infer.Trace_ELBO(max_plate_nesting=3),\n",
    ")\n",
    "\n",
    "\n",
    "# keep track of anything meaningful here\n",
    "beta1s, beta1_vars, beta0s, beta0_vars, dm, dv, api, bpi, pis, losses = (\n",
    "    [] for _ in range(10)\n",
    ")\n",
    "\n",
    "for t in range(num_steps):\n",
    "    losses.append(svi.step(data))\n",
    "    if t == 1:\n",
    "        print(pyro.get_param_store())\n",
    "    beta1s.append(pyro.param(\"AutoNormal.locs.beta_1\").clone())\n",
    "    beta1_vars.append(pyro.param(\"AutoNormal.scales.beta_1\"))\n",
    "    beta0s.append(pyro.param(\"AutoNormal.locs.beta_0\").clone())\n",
    "    beta0_vars.append(pyro.param(\"AutoNormal.scales.beta_0\"))\n",
    "    dm.append(pyro.param(\"AutoNormal.locs.dispersion\").clone())\n",
    "    dv.append(pyro.param(\"AutoNormal.scales.dispersion\"))\n",
    "    api.append(pyro.param(\"alpha_pi\").clone().detach())\n",
    "    bpi.append(pyro.param(\"beta_pi\").clone().detach())\n",
    "    a = pyro.param(\"alpha_pi\").clone().detach()\n",
    "    b = pyro.param(\"beta_pi\").clone().detach()\n",
    "    pis.append(a / (a + b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jd_pyro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3cdaaedb1fa9f528ee10659353db3bd8a1bd8f0894a9cc3b9b974535b18ad13"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
